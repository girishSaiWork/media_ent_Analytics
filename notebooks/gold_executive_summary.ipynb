{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "342a8465-e4e8-4131-a6fc-7a8f2e6865f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold Layer - Executive Summary\n",
    "High-level KPIs and metrics for executive dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82103269-cdfd-40d5-ac0e-ab14bbf97260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, count, sum, avg, max, min, round, current_timestamp, current_date,\n",
    "    when, lit, coalesce\n",
    ")\n",
    "from pyspark.sql import Window\n",
    "from config import TARGET_CATALOG, SILVER_SCHEMA, GOLD_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cdfb42a-eaab-42fc-9619-930416672a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_executive_summary():\n",
    "    \"\"\"\n",
    "    Create executive summary table with key business metrics\n",
    "    \n",
    "    Metrics: total_views, avg_completion_rate, avg_performance_score,\n",
    "             active_devices, active_locations, qos_score, market_potential\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read all silver tables\n",
    "    assets = spark.table(f\"{TARGET_CATALOG}.{SILVER_SCHEMA}.assets\")\n",
    "    metrics = spark.table(f\"{TARGET_CATALOG}.{SILVER_SCHEMA}.metrics\")\n",
    "    devices = spark.table(f\"{TARGET_CATALOG}.{SILVER_SCHEMA}.devices\")\n",
    "    geo = spark.table(f\"{TARGET_CATALOG}.{SILVER_SCHEMA}.geo\")\n",
    "    delivery = spark.table(f\"{TARGET_CATALOG}.{SILVER_SCHEMA}.delivery\")\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    metrics_summary = metrics.agg(\n",
    "        avg(\"performance_score\").alias(\"avg_performance_score\"),\n",
    "        count(\"*\").alias(\"total_streams\"),\n",
    "        sum(\"rebuffering_count\").alias(\"total_buffering_events\")\n",
    "    )\n",
    "    \n",
    "    # Device metrics\n",
    "    device_summary = devices.agg(\n",
    "        count(\"device_id\").alias(\"active_devices\"),\n",
    "        count(when(col(\"device_form_factor\") == \"Mobile\", 1)).alias(\"mobile_devices\"),\n",
    "        count(when(col(\"device_form_factor\") == \"Desktop\", 1)).alias(\"desktop_devices\"),\n",
    "        count(when(col(\"is_bot_likely\") == True, 1)).alias(\"bot_devices\")\n",
    "    )\n",
    "    \n",
    "    # Geographic metrics\n",
    "    geo_summary = geo.agg(\n",
    "        count(\"location_id\").alias(\"active_locations\"),\n",
    "        sum(\"population\").alias(\"total_population\"),\n",
    "        count(when(col(\"population_density_tier\") == \"Megacity\", 1)).alias(\"megacity_locations\"),\n",
    "        count(when(col(\"coordinates_valid\") == False, 1)).alias(\"invalid_coordinates\")\n",
    "    )\n",
    "    \n",
    "    # Content metrics\n",
    "    content_summary = assets.agg(\n",
    "        count(\"content_id\").alias(\"total_content\"),\n",
    "        count(when(col(\"content_freshness\") == \"New\", 1)).alias(\"new_content\"),\n",
    "        count(when(col(\"content_freshness\") == \"Archive\", 1)).alias(\"archive_content\"),\n",
    "        avg(\"content_completeness_score\").alias(\"avg_content_completeness\")\n",
    "    )\n",
    "    \n",
    "    # Delivery metrics\n",
    "    delivery_summary = delivery.agg(\n",
    "        avg(\"delivery_quality_score\").alias(\"avg_delivery_quality_score\"),\n",
    "        count(when(col(\"cache_effectiveness\") == \"Effective\", 1)).alias(\"effective_cache_count\"),\n",
    "        count(\"delivery_id\").alias(\"total_deliveries\")\n",
    "    )\n",
    "    \n",
    "    # Combine all metrics\n",
    "    gold = metrics_summary.crossJoin(device_summary) \\\n",
    "                          .crossJoin(geo_summary) \\\n",
    "                          .crossJoin(content_summary) \\\n",
    "                          .crossJoin(delivery_summary)\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    gold = gold.withColumn(\"cache_hit_rate\",\n",
    "        round((col(\"effective_cache_count\") / col(\"total_deliveries\")) * 100, 2)\n",
    "    )\n",
    "    \n",
    "    gold = gold.withColumn(\"buffering_rate\",\n",
    "        round(col(\"total_buffering_events\") / col(\"total_streams\"), 2)\n",
    "    )\n",
    "    \n",
    "    gold = gold.withColumn(\"mobile_percentage\",\n",
    "        round((col(\"mobile_devices\") / col(\"active_devices\")) * 100, 2)\n",
    "    )\n",
    "    \n",
    "    gold = gold.withColumn(\"bot_percentage\",\n",
    "        round((col(\"bot_devices\") / col(\"active_devices\")) * 100, 2)\n",
    "    )\n",
    "    \n",
    "    gold = gold.withColumn(\"data_quality_score\",\n",
    "        round(\n",
    "            (when(col(\"invalid_coordinates\") == 0, 1.0).otherwise(0.8)) * 0.3 +\n",
    "            (col(\"avg_content_completeness\") * 0.3) +\n",
    "            (when(col(\"bot_percentage\") < 5, 1.0).otherwise(0.7) * 0.4),\n",
    "            2\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Overall health score\n",
    "    gold = gold.withColumn(\"overall_health_score\",\n",
    "        round(\n",
    "            (col(\"avg_delivery_quality_score\") * 0.2) +\n",
    "            (col(\"data_quality_score\") * 0.2),\n",
    "            2\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Health status\n",
    "    gold = gold.withColumn(\"overall_health_status\",\n",
    "        when(col(\"overall_health_score\") >= 0.8, \"Excellent\")\n",
    "        .when(col(\"overall_health_score\") >= 0.6, \"Good\")\n",
    "        .when(col(\"overall_health_score\") >= 0.4, \"Fair\")\n",
    "        .otherwise(\"Poor\")\n",
    "    )\n",
    "    \n",
    "    # Add metadata\n",
    "    gold = gold.withColumn(\"analytics_timestamp\", current_timestamp()) \\\n",
    "               .withColumn(\"analytics_date\", current_date())\n",
    "    \n",
    "    # Write to gold\n",
    "    target_table = f\"{TARGET_CATALOG}.{GOLD_SCHEMA}.executive_summary\"\n",
    "    gold.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(target_table)\n",
    "    \n",
    "    print(f\"Executive Summary created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad9a4bbc-a1ce-4b34-8e73-97734ee1f2fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executive Summary created\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_CATALOG}.{GOLD_SCHEMA}\")\n",
    "create_executive_summary()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gold_executive_summary",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}