{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c07dca55-2a82-4e1d-8ae9-db4d74f766e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer - Metrics Transformation\n",
    "Business transformations for performance analytics and KPI calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb17855b-509f-4008-9a24-cb19931eadc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, trim, upper, lower, coalesce, when, current_timestamp, current_date,\n",
    "     lit, round, abs, sqrt, pow\n",
    ")\n",
    "from config import TARGET_CATALOG, BRONZE_SCHEMA, SILVER_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d23acec4-383b-4bef-bf7d-1f5a47e10f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_metrics():\n",
    "    \"\"\"\n",
    "    Transform metrics with business logic:\n",
    "    - Performance KPI calculation and normalization\n",
    "    - Metric quality validation\n",
    "    - Anomaly detection flags\n",
    "    - Performance tier classification\n",
    "    - Trend indicators\n",
    "    - Business metric aggregation\n",
    "    \"\"\"\n",
    "    \n",
    "    df = spark.table(f\"{TARGET_CATALOG}.{BRONZE_SCHEMA}.metrics\")\n",
    "    \n",
    "    # Standardize column names\n",
    "    df = df.select([col(c).alias(c.lower()) for c in df.columns])\n",
    "    \n",
    "    # Trim string columns\n",
    "    string_cols = [f.name for f in df.schema.fields if f.dataType.typeName() == 'string']\n",
    "    for col_name in string_cols:\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, trim(col(col_name)))\n",
    "    \n",
    "    # Get numeric columns for metric processing\n",
    "    numeric_cols = [f.name for f in df.schema.fields if f.dataType.typeName() in ['double', 'float', 'long', 'integer']]\n",
    "    \n",
    "    # Round numeric metrics to 2 decimal places\n",
    "    for col_name in numeric_cols:\n",
    "        if col_name not in ['load_timestamp', 'load_date', 'data_quality_score']:\n",
    "            df = df.withColumn(col_name, round(col(col_name), 2))\n",
    "    \n",
    "    # Validate metric values - filter out negative values for KPIs\n",
    "    for col_name in numeric_cols:\n",
    "        if col_name not in ['load_timestamp', 'load_date', 'data_quality_score']:\n",
    "            df = df.filter(col(col_name) >= 0)\n",
    "    \n",
    "    # Performance tier classification based on typical streaming metrics\n",
    "    # Assuming columns like views, completion_rate, avg_bitrate, etc.\n",
    "    \n",
    "    # Views/Engagement tier\n",
    "    if \"views\" in df.columns:\n",
    "        df = df.withColumn(\"engagement_tier\",\n",
    "            when(col(\"views\") >= 100000, \"High\")\n",
    "                .when(col(\"views\") >= 10000, \"Medium\")\n",
    "                .when(col(\"views\") >= 1000, \"Low\")\n",
    "                .otherwise(\"Minimal\")\n",
    "        )\n",
    "    \n",
    "    # Completion rate classification\n",
    "    if \"completion_rate\" in df.columns:\n",
    "        df = df.withColumn(\"completion_rate_category\",\n",
    "            when(col(\"completion_rate\") >= 0.8, \"Excellent\")\n",
    "                .when(col(\"completion_rate\") >= 0.6, \"Good\")\n",
    "                .when(col(\"completion_rate\") >= 0.4, \"Fair\")\n",
    "                .otherwise(\"Poor\")\n",
    "        )\n",
    "    \n",
    "    # Bitrate quality classification\n",
    "    if \"avg_bitrate\" in df.columns:\n",
    "        df = df.withColumn(\"bitrate_quality\",\n",
    "            when(col(\"avg_bitrate\") >= 5000, \"4K\")\n",
    "                .when(col(\"avg_bitrate\") >= 2500, \"1080p\")\n",
    "                .when(col(\"avg_bitrate\") >= 1500, \"720p\")\n",
    "                .when(col(\"avg_bitrate\") >= 800, \"480p\")\n",
    "                .otherwise(\"Low\")\n",
    "        )\n",
    "    \n",
    "    # Buffering impact assessment\n",
    "    if \"buffering_events\" in df.columns:\n",
    "        df = df.withColumn(\"buffering_impact\",\n",
    "            when(col(\"buffering_events\") == 0, \"None\")\n",
    "                .when(col(\"buffering_events\") <= 2, \"Minimal\")\n",
    "                .when(col(\"buffering_events\") <= 5, \"Moderate\")\n",
    "                .otherwise(\"Severe\")\n",
    "        )\n",
    "    \n",
    "    # Anomaly detection - flag unusual metric values\n",
    "    if \"avg_bitrate\" in df.columns:\n",
    "        df = df.withColumn(\"bitrate_anomaly\",\n",
    "            when((col(\"avg_bitrate\") > 10000) | (col(\"avg_bitrate\") < 100), True).otherwise(False)\n",
    "        )\n",
    "    \n",
    "    if \"completion_rate\" in df.columns:\n",
    "        df = df.withColumn(\"completion_rate_anomaly\",\n",
    "            when((col(\"completion_rate\") > 1.0) | (col(\"completion_rate\") < 0), True).otherwise(False)\n",
    "        )\n",
    "    \n",
    "    # Performance score calculation (0-100)\n",
    "    performance_score = lit(0)\n",
    "    \n",
    "    if \"completion_rate\" in df.columns:\n",
    "        performance_score = performance_score + (col(\"completion_rate\") * 40)\n",
    "    \n",
    "    if \"avg_bitrate\" in df.columns:\n",
    "        performance_score = performance_score + (when(col(\"avg_bitrate\") >= 2500, 30).otherwise(col(\"avg_bitrate\") / 2500 * 30))\n",
    "    \n",
    "    if \"buffering_events\" in df.columns:\n",
    "        performance_score = performance_score + (when(col(\"buffering_events\") == 0, 30).otherwise(30 - (col(\"buffering_events\") * 5)))\n",
    "    \n",
    "    df = df.withColumn(\"performance_score\", round(performance_score, 2))\n",
    "    \n",
    "    # Performance health status\n",
    "    df = df.withColumn(\"performance_health\",\n",
    "        when(col(\"performance_score\") >= 85, \"Excellent\")\n",
    "            .when(col(\"performance_score\") >= 70, \"Good\")\n",
    "            .when(col(\"performance_score\") >= 50, \"Fair\")\n",
    "            .otherwise(\"Poor\")\n",
    "    )\n",
    "    \n",
    "    # Remove duplicates\n",
    "    if \"metric_id\" in df.columns:\n",
    "        df = df.dropDuplicates([\"metric_id\"])\n",
    "    \n",
    "    # Add transformation metadata\n",
    "    df = df.withColumn(\"transformed_timestamp\", current_timestamp()) \\\n",
    "           .withColumn(\"transformed_date\", current_date())\n",
    "    \n",
    "    # Write to silver\n",
    "    target_table = f\"{TARGET_CATALOG}.{SILVER_SCHEMA}.metrics\"\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(target_table)\n",
    "    \n",
    "    print(f\"Metrics transformed: {df.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "045f2c79-46a8-4592-b501-ab6a056ab96d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_CATALOG}.{SILVER_SCHEMA}\")\n",
    "transform_metrics()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_metrics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
